---
title: "pml_cpw"
author: "Dhruv K Pant"
date: "June 18, 2014"
output: html_document
---
## Prediction Analysis of personal activity data 

### Summary 
The goal of the following analysis is to understand the variables which are important in 
the data on personal activity with the aim of predicting which class  a group of persons belong to given 
new data on their personal activity.  

First, we need to clean that data, which has several NAs as entries. We identify the columns in the training 
data matrix which have a high percentage of NAs and remove those columns from further analysis. Additionally, 
only those columns which have arm/forearm/dumbbell/belt are retained as predictor variables. The accelerometers 
were installed in these locations and therefore these would be the relevant variables to process.
In a similar manner to the training data, variables from the testing dataset are removed and the
variables (53 of them) which are common to the testing and the training datasets are kept for building a prediction model.

Correlation among the variables is explored next, in order to assess multicollinearity and to remove highly correlated 
variables. Those variable pairs which have a Pearson correlation coefficient of 0.8 or higher are identified. Potentially
one variable of each pair could be removed.

A seed is set using set.seed function, to ensure that the computation is reproducible.
A classification and regression tree is built in two ways- 
1) doing a preprocessing of the data by centering and scaling the data and 
2) without doing the centering and scaling. For the models generated, the importance of the variables is assessed.
This identified 14 variables as being important in the prediction.

Next, two other algorithms namely boosting and Random Forests and used to generate models for prediction. These are 
chosen because they are robust models for doing prediction on non-linear data.
In one approach, all 53 variables are used in the model fitting. In the other approach, 14 variables (identified 
as important from the 'rpart' analysis) are used. 
Cross validation is done within the Random forest computation using a 3-fold cross-validation. The out of sample
error is assessed from the confusion matrix. A confusion matrix enables one to identify how good the predictions are.

The result indicates that the prediction accuracy is better in the bigger (53 variable) model than 
the 14 variable model, but not by much. The choice of variable selection would be a tradeoff between slightly 
improved accuracy and processing time. Further refinement of the predictor model might including combining 
various predictors to reduce the out of sample error while  minimizing overfitting.



### Read in input data 
```{r input_data,cache=TRUE}
tr <- read.csv("pml-training.csv")
te <- read.csv("pml-testing.csv")
```

### Explore and preprocess the data
```{r exploration}
#str(tr); dim(tr)
#colnames(tr)
table(tr$classe)

```

### Identifying NA's 
```{r remove_na_training,cache=T}
### On the training set
cols.w.nas <- apply(tr,2,function(x) sum(is.na(x)))
### Remove columns which have high percentage of NAs
cols.to.remove <- names(cols.w.nas[cols.w.nas>0])
tr2 <- tr[,!colnames(tr)%in%cols.to.remove]
### keep variables pertaining to belt/forearm/arm/dumbbell
ind1 <- grepl("_arm|_forearm|_dumbbell|_belt",colnames(tr2))
tr3 <- cbind(tr2[,ind1],classe=tr2$classe)
#ind2 <- !grepl("yaw",colnames(tr3))
#tr4 <- tr3[,ind2]
#x <- head(tr4,n=100)
cn.tr <- colnames(tr3)

```

```{r remove_na_testing,cache=T}
### On the testing set
cols.w.nas <- apply(te,2,function(x) sum(is.na(x)))
cols.to.remove <- names(cols.w.nas[cols.w.nas>0])
te2 <- te[,!colnames(te)%in%cols.to.remove]
ind1 <- grepl("_arm|_forearm|_dumbbell|_belt",colnames(te2))
te3 <- cbind(te2[,ind1],problem_id=te2$problem_id)
cn.te <- colnames(te3)

common <- intersect(cn.tr,cn.te)
```


### Variable selection
The variables which are common to the training and testing datasets are kept for further processing.
``` {r variable_selection}
tr4 <- cbind(tr3[,colnames(tr3)%in%common],classe=tr3$classe)
te4 <- cbind(te3[,colnames(te3)%in%common],problem_id=te3$problem_id)

```

### Explore correlation among variables
Several variables can be correlated. This would affect the model building. Such variables are identified below
using the 'cor' function using Pearson correlation. Those variable pairs which have a correlation of > 0.8 need
to be looked at more closely and appropriately removed.
``` {r corr}
x <- cor(subset(tr4,select=-classe))
diag(x) <- 0
### the correlated variables
head(which(abs(x)>0.8,arr.ind=T))
### Look at a feature plot of response with a few predictors
six.cols <- rownames(head(which(abs(x)>0.8,arr.ind=T)))
tmp1 <- head(data.frame(tr4[,colnames(tr4)%in%six.cols],classe=tr4$classe),n=100)
tmp2 <- tail(data.frame(tr4[,colnames(tr4)%in%six.cols],classe=tr4$classe),n=100)
tmp <- rbind(tmp1,tmp2)
require(caret)
featurePlot(y=tmp$classe,x=subset(tmp,select=-classe),plot="pairs")
```


### Fit different models on the data 
```{r models, cache=TRUE}
### center and scale, log transformation, Box-Cox??
require(caret)
set.seed(12365)

### Generate a classification and regression tree
mod.rpart.scaled <- train(classe~., data=tr4,preProcess=c("center","scale"),method="rpart")
mod.rpart <- train(classe~., data=tr4,method="rpart")
predict(mod.rpart.scaled,te4)

### Boosting, Random Forest on 53 variables.
### For the Random forest model, apply a 3-fold cross validation
mod.rf <- train(classe~., data=tr4,method="rf",trControl=trainControl(method="cv"),number=3)
mod.gbm <- train(classe~., data=tr4,method="gbm",verbose=F)   ### takes v long
mod.rf.oob <- train(classe~., data=tr4,method="rf",trControl=trainControl(method="oob"),number=3)

### Assess variable importance from the rpart models ###
### and consider only those variables for the RF and boosting models 
tmp <- varImp(mod.rpart)
imp.var <- rownames(tmp$importance)[tmp$importance>0]
tr5 <- cbind(tr4[,colnames(tr4)%in%imp.var],classe=tr4$classe)
te5 <- cbind(te4[,colnames(te4)%in%imp.var],problem_id=te4$problem_id)
#tr6 <- head(tr5,n=1000)
#featurePlot(y=tr6$classe,x=subset(tr6,select=-classe),plot="pairs")

### Now do Boosting, Random forests on 14 variables (identified as important from a classification 
### and regression tree model) to compare with the more exhaustive variable list (of 53)
mod.rf.small <- train(classe~.,data=tr5,method="rf",trControl=trainControl(method="cv"),number=3)

```



### Predictions and Error analysis
``` {r predict,cache=TRUE}
pred.gbm <- predict(mod.gbm,te4);pred.gbm
pred.rf <- predict(mod.rf,te4); pred.rf
#pred.rf.oob <- predict(mod.rf.oob,te4)
pred.rf.small <- predict(mod.rf.small,te5); pred.rf.small

### Look at confusion matrix for prediction done with 53 variables
confusionMatrix(mod.rf)

### Look at confusion matrix for prediction done with only 14 variables
confusionMatrix(mod.rf.small)

### store the predictions in object 'answers' for the course project submission
answers <- pred.rf
``` 





